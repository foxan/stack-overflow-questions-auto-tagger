{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will focus on feature extraction from the two text columns, i.e. title and body, so that the data set will be ready for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOME_DIR = os.curdir\n",
    "DATA_DIR = os.path.join(HOME_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.max_colwidth = 255\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"{DATA_DIR}/tp-2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>body_tokenized</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170505</th>\n",
       "      <td>6628270</td>\n",
       "      <td>[view, renders, correctly, browser, tests, fail, helper, method]</td>\n",
       "      <td>[simple, view, helper, defines, title, everything, works, fine, pull, view, browser, rspec, tests, fail, tests, describe, pagescontroller, ror, sample, app, end, describe, get, successful, get, end, right, title, get, title, content, +, home, end, end...</td>\n",
       "      <td>[ruby-on-rails, view, rspec, helper]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181127</th>\n",
       "      <td>37999670</td>\n",
       "      <td>[parsing, linux, iscsi, python, nested, dictionaries]</td>\n",
       "      <td>[writing, script, involves, multipath, objects, standard, configuration, file, example, #, basic, configuration, file, examples, device, mapper, #, multipath, #, #, use, user, friendly, names, instead, using, wwids, names, defaults, yes, #, #, devices...</td>\n",
       "      <td>[python, dictionary, config, iscsi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408156</th>\n",
       "      <td>14425410</td>\n",
       "      <td>[unable, handle, kernel, paging, request, x, intercepting, system, call]</td>\n",
       "      <td>[possible, duplicate, linux, kernel, system, call, hooking, example, trying, hook, system, calls, kernel, got, basic, idea, system, call, trying, intercept, fork, found, address, turned, wrote, module, #, include, #, include, #, include, #, include, #...</td>\n",
       "      <td>[c, linux, kernel-module, kernel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330749</th>\n",
       "      <td>11898920</td>\n",
       "      <td>[working]</td>\n",
       "      <td>[using, url, routing, structure, web, use, url, routing, especially, multi, segment, css, js, file, used, work, void, routemap, routecollection, route, false, resource, work, resource, work, work, work, guide, key, key, void, object, sender, eventargs...</td>\n",
       "      <td>[asp.net, routing, url-routing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012433</th>\n",
       "      <td>33451620</td>\n",
       "      <td>[hibernate, findbyproperty, use, different, types]</td>\n",
       "      <td>[trying, write, search, using, hibernate, would, run, search, different, types, variables, model, movie, properties, title, director, genre, year, title, director, genre, strings, year, int, jsp, file, select, choose, property, want, search, text, inp...</td>\n",
       "      <td>[java, hibernate-criteria]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  \\\n",
       "170505    6628270   \n",
       "1181127  37999670   \n",
       "408156   14425410   \n",
       "330749   11898920   \n",
       "1012433  33451620   \n",
       "\n",
       "                                                                  title_tokenized  \\\n",
       "170505           [view, renders, correctly, browser, tests, fail, helper, method]   \n",
       "1181127                     [parsing, linux, iscsi, python, nested, dictionaries]   \n",
       "408156   [unable, handle, kernel, paging, request, x, intercepting, system, call]   \n",
       "330749                                                                  [working]   \n",
       "1012433                        [hibernate, findbyproperty, use, different, types]   \n",
       "\n",
       "                                                                                                                                                                                                                                                         body_tokenized  \\\n",
       "170505   [simple, view, helper, defines, title, everything, works, fine, pull, view, browser, rspec, tests, fail, tests, describe, pagescontroller, ror, sample, app, end, describe, get, successful, get, end, right, title, get, title, content, +, home, end, end...   \n",
       "1181127  [writing, script, involves, multipath, objects, standard, configuration, file, example, #, basic, configuration, file, examples, device, mapper, #, multipath, #, #, use, user, friendly, names, instead, using, wwids, names, defaults, yes, #, #, devices...   \n",
       "408156   [possible, duplicate, linux, kernel, system, call, hooking, example, trying, hook, system, calls, kernel, got, basic, idea, system, call, trying, intercept, fork, found, address, turned, wrote, module, #, include, #, include, #, include, #, include, #...   \n",
       "330749   [using, url, routing, structure, web, use, url, routing, especially, multi, segment, css, js, file, used, work, void, routemap, routecollection, route, false, resource, work, resource, work, work, work, guide, key, key, void, object, sender, eventargs...   \n",
       "1012433  [trying, write, search, using, hibernate, would, run, search, different, types, variables, model, movie, properties, title, director, genre, year, title, director, genre, strings, year, int, jsp, file, select, choose, property, want, search, text, inp...   \n",
       "\n",
       "                                         tags  \n",
       "170505   [ruby-on-rails, view, rspec, helper]  \n",
       "1181127   [python, dictionary, config, iscsi]  \n",
       "408156      [c, linux, kernel-module, kernel]  \n",
       "330749        [asp.net, routing, url-routing]  \n",
       "1012433            [java, hibernate-criteria]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of tags (i.e. classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38147"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tag_count = Counter()\n",
    "\n",
    "def count_tag(tags):\n",
    "    for tag in tags:\n",
    "        tag_count[tag] += 1\n",
    "\n",
    "df[\"tags\"].apply(count_tag)\n",
    "\n",
    "len(tag_count.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are over 38,000 tags in the dataset, which is too much for a multi-label classification, I will only keep data with the top 4,000 tags (which will cover 90% of the questions), as suggested in exploratory data analysis earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264216/1264216 [00:46<00:00, 27418.12it/s]\n"
     ]
    }
   ],
   "source": [
    "most_common_tags = [count[0] for count in tag_count.most_common(4000)]\n",
    "df[\"tags\"] = df[\"tags\"].progress_apply(lambda tags: [tag for tag in tags if tag in most_common_tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250951, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"tags\"].map(lambda tags: len(tags) > 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 13,265 rows of data will be dropped while number of classes is reduced from 38,147 to 4,000, which is great!\n"
     ]
    }
   ],
   "source": [
    "print(f\"Only {1264216 - 1250951:,} rows of data will be dropped while number of classes is reduced from {len(tag_count.values()):,} to 4,000, which is great!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"tags\"].map(lambda tags: len(tags) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "df.to_pickle(f\"{DATA_DIR}/fe-1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"{DATA_DIR}/fe-1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# we have already tokenize the text so we need a dummy one to bypass tokenization\n",
    "def dummy_tokenizer(string): return string\n",
    "\n",
    "# we will only get the 10,000 most common words for title to limit size of dataset\n",
    "title_vectorizer = TfidfVectorizer(tokenizer=dummy_tokenizer, lowercase=False, max_features=10000)\n",
    "x_title = title_vectorizer.fit_transform(df[\"title_tokenized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will get the 100,000 most common words for body\n",
    "body_vectorizer = TfidfVectorizer(tokenizer=dummy_tokenizer, lowercase=False, max_features=100000)\n",
    "x_body = body_vectorizer.fit_transform(df[\"body_tokenized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>body_tokenized</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>930</td>\n",
       "      <td>[connect, database, loop, recordset, c#]</td>\n",
       "      <td>[simplest, way, connect, query, database, set, records, c#]</td>\n",
       "      <td>[c#, database, loops, connection]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                           title_tokenized  \\\n",
       "10  930  [connect, database, loop, recordset, c#]   \n",
       "\n",
       "                                                 body_tokenized  \\\n",
       "10  [simplest, way, connect, query, database, set, records, c#]   \n",
       "\n",
       "                                 tags  \n",
       "10  [c#, database, loops, connection]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recordset    0.668319\n",
       "connect      0.433807\n",
       "loop         0.376748\n",
       "database     0.338899\n",
       "c#           0.329195\n",
       "Name: 10, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_title[:11].toarray(), columns=title_vectorizer.get_feature_names()) \\\n",
    "  .iloc[10].sort_values(ascending=False).where(lambda v: v > 0).dropna().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simplest    0.557716\n",
       "records     0.401627\n",
       "connect     0.373088\n",
       "c#          0.356147\n",
       "query       0.294480\n",
       "database    0.282837\n",
       "set         0.231035\n",
       "way         0.203765\n",
       "Name: 10, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_body[:11].toarray(), columns=body_vectorizer.get_feature_names()) \\\n",
    "  .iloc[10].sort_values(ascending=False).where(lambda v: v > 0).dropna().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not that bad, as we can see keywords from the feature like `connect`, `loop`, `c#` and `database`, which are similar to the actual tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concantenate dataset and train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a problematic tag named \"nan\" which causes string comparison error\n",
    "df[\"tags\"] = df[\"tags\"].apply(lambda tags: [tag if not isinstance(tag, float) else \"nan\" for tag in tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give a weight of 2 to title as it should contain more important words than body\n",
    "x_title = x_title * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = hstack([x_title, x_body])\n",
    "y = df[[\"tags\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multi_label_binarizer = MultiLabelBinarizer()\n",
    "y = multi_label_binarizer.fit_transform(y[\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/y_classes.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(X_train, f\"{DATA_DIR}/x_train.pkl\")\n",
    "joblib.dump(X_test, f\"{DATA_DIR}/x_test.pkl\")\n",
    "joblib.dump(y_train, f\"{DATA_DIR}/y_train.pkl\")\n",
    "joblib.dump(y_test, f\"{DATA_DIR}/y_test.pkl\")\n",
    "joblib.dump(multi_label_binarizer.classes_, f\"{DATA_DIR}/y_classes.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
